<html>
  <head>
    <title>Steve Yadlowsky</title>
  </head>
  <body>
    <img align="left" height="200px" style="padding:9px 15px;" src="portrait.jpg" />
    <h1>Steve Yadlowsky</h1>
    <h2>
        Research Scientist, Google DeepMind
        <br />
        Language Modeling, Foundation Models, Statistics
    </h2>
    &lt;lastname@google.com&gt;
    <p>
     Currently, I am working on Google DeepMind's Gemini project. My research interests are
     focused on understanding how data used for model training and evaluation affects the models'
     capabilities. Recently, I've been focused on
     evaluating and tracking progress in the models' capabilities, especially in factuality,
     mathematics and reasoning. This work has taught me a lot about the core challenges and how
     high quality data can improve model performance.
    </p>
    <p>
     Before this, I worked on statistics and machine learning challenges in the area of causal inference. I focused
     particularly on high dimensional problems and understanding the interplay between machine learning models and
     the statistics of causal questions. I applied many of the approaches developed the recommender systems, A/B testing
     frameworks, and healthcare applications.
    </p>
    <p>
      I finished my PhD at Stanford University in June 2020. There, I was fortunate to be advised by <a href="https://web.stanford.edu/~basus/">Dr. Sanjay
      Basu</a> and <a href="https://web.stanford.edu/~lutian/Bio.HTML">Lu Tian</a>,
      collaborate with <a href="http://stanford.edu/~jduchi/">John
      C. Duchi</a> and his group on topics related to machine learning and
      stochastic optimization, and collaborate with <a href="https://shahlab.stanford.edu/">Nigam Shah</a>
      and his group on the use of causal methods in clinical informatics.
    </p>
    <h3>
    Blog
    </h3>
    <p>
    I have started a blog <i><a href="/blog">Treatments and Observations</a></i> to help explain some valuable technical insights from my statistical research in a more pedagogical fashion than typically expected of statistics journal venues.
    </p>
    <h3>
    Education
    </h3>
    <p>
      Ph.D., Dept. of Electrical Engineering, Stanford University <br />
      M.S., Dept. of Statistics, Stanford University <br />
      B.S., Dept. of Electrical Engineering and Computer Sciences, UC Berkeley
    </p>
    <h3>Publications</h3>
    <h4>Submitted / Preprints</h4>
    <p>
      S. Yadlowsky, L. Doshi, N. Triperaneni.
      Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models.
      [<a href="https://arxiv.org/abs/2311.00871">arXiv</a>].
      <br /><br />
      T. Cai, H. Namkoong, S. Yadlowsky.
      Diagnosing Model Performance Under Distribution Shift
      [<a href="https://arxiv.org/abs/2311.00871">arXiv</a>].
      <br /><br />
      N. Tripuraneni, L. Richardson, A. D'Amour, J. Soriano, S Yadlowsky.
      Choosing a Proxy Metric from Past Experiments.
      [<a href="https://arxiv.org/abs/2309.07893">arXiv</a>].
      <br /><br />
      S. Yadlowsky.
      Explaining Practical Differences Between Treatment Effect Estimators with High Dimensional Asymptotics.
      [<a href="https://arxiv.org/abs/2203.12538">arXiv</a>].
      <br /><br />
      S. Yadlowsky*, S. Fleming*, N. Shah, E. Brunskill, S. Wager.
      Evaluting Treatment Prioritization Rules via Rank-Weighted Average Treatment Effects.
      [<a href="https://arxiv.org/abs/2111.07966">arXiv</a>].
      <br /><br />
      M. Oberst, A. D'Amour, M. Chen, Y. Wang, D. Sontag, S. Yadlowsky.
      Bias-robust Integration of Observational and Experimental Estimators.
      [<a href="https://arxiv.org/abs/2205.10467">arXiv</a>].
      <br /><br />
    </p>
    <h4>Published</h4>
    <p>
      D. Bruns-Smith, A. D'Amour, A. Feller, S. Yadlowsky.
      Tailored Overlap for Learning Under Distribution Shift.
      <i>DistShift Workshop</i> at NeurIPS, 2022.
      [<a href="https://openreview.net/forum?id=8-n8hh2Th_">OpenReview</a>].
      <br /><br />
      T. Sellam*, S. Yadlowsky*, I. Tenny*, J. Wei, N. Saphra, A. D'Amour, T. Linzen, J. Bastings, I. Turc, J. Eisenstein, D. Das, E. Pavlick.
      The MultiBERTs: BERT Reproductions for Robustness Analysis.
      <i>International Conference on Learning Representations</i> (ICLR), 2022.
      [<a href="https://arxiv.org/abs/2106.16163">arXiv</a>].
      [<a href="https://openreview.net/forum?id=K0E_F0gFDgA">OpenReview</a>].
      <br /><br />
      A. D'Amour, K. Heller, D. Moldovan, et al..
      Underspecification Presents Challenges for Credibility in Modern Machine Learning.
      <i>Journal of Machine Learning Research</i> (JMLR), 2022.
      [<a href="https://arxiv.org/abs/2011.03395">arXiv</a>].
      <br /><br />
      E. Steinberg, N. Ignatiadis, S. Yadlowsky, Y. Xu, N.H. Shah.
      Using public clinical trial reports to evaluate observational study methods.
      [<a href="https://arxiv.org/abs/2006.14102">arXiv</a>].
      <i>BMC Medical Research Methodology</i>, 2023.
      <br /><br />
      S. Yadlowsky, H. Namkoong, S. Basu, J.C. Duchi, L. Tian.
      Bounds on the Conditional and Average Treatment Effect with Unobserved Confounding Factors. <i>Annals of Statistics</i>, 2022.
      [<a href="https://arxiv.org/abs/1808.09521">arXiv</a>].
      <br /><br />
      S. Yadlowsky, T. Yun, C. McLean, A. D'Amour.
      SLOE: A Faster Method for Statistical Inference in High-Dimensional Logistic Regression.
      <i>Neural Information Processing Systems</i> (NeurIPS), 2021. 
      [<a href="https://arxiv.org/abs/2103.12725">arXiv</a>]
      [<a href="https://github.com/google-research/sloe-logistic">code</a>].
      <br /><br />
      V. Veitch, A. D'Amour, S. Yadlowsky, J. Eisenstein.
      Counterfactual Invariance to Spurious Correlations: Why and How to Pass Stress Tests.
      <i>Neural Information Processing Systems</i> (NeurIPS), 2021. 
      [<a href="https://arxiv.org/abs/2106.00545">arXiv</a>].
      <br /><br />
      C. Nagpal, S. Yadlowsky, N. Rostamzadeh, K. Heller.
      Deep Cox Mixtures for Survival Regression.
      <i>Machine Learning for Healthcare</i> (MLHC), 2021. 
      [<a href="https://arxiv.org/abs/2101.06536">arXiv</a>]
      <br /><br />
      H. Namkoong*, R. Keramati*, S. Yadlowsky*, E. Brunskill.
      Off-policy Policy Evaluation For Sequential Decisions Under Unobserved Confounding.
      <i>Neural Information Processing Systems</i> (NeurIPS), 2020. 
      [<a href="https://arxiv.org/abs/2003.05623">arXiv</a>]
      [<a href="https://github.com/StanfordAI4HI/off_policy_confounding">code</a>]
      <br /><br />
      S. Yadlowsky, F. Pellegrini, F. Lionetto, S. Braune, L. Tian.
      Estimation and Validation of Ratio-based Conditional Average Treatment Effects Using Observational Data.
      <i>Journal of the American Statistical Association</i>. 28 May 2020.
      doi: <a href="https://doi.org/10.1080/01621459.2020.1772080">10.1080/01621459.2020.1772080</a>.
      [<a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080">online</a>]
      [<a href="https://arxiv.org/abs/1912.06977">arXiv</a>]
      <br /><br />
      Yadlowsky S, Basu S, Tian L.
      A calibration metric for risk scores with survival data. <i>Machine
      Learning for Healthcare, 2019</i>.
      [<a href="https://github.com/syadlowsky/calibration">code</a>]
      [<a href="https://www.mlforhc.org/s/Yadlowsky.pdf">pdf</a>].
      <br /><br />
      S. Kashyap S, S. Gombar S, S. Yadlowsky, A. Callahan, J. Fries, B.A. Pinsky, N.H. Shah.
      Measure what matters: Counts of hospitalized patients are a better metric for health system capacity planning for a reopening.
      <i>Journal of the American Medical Informatics Association</i>, 17 June 2020. doi: <a href="https://doi.org/10.1093/jamia/ocaa076">10.1093/jamia/ocaa076</a>.
      [<a href="https://www.medrxiv.org/content/10.1101/2020.04.19.20072017v2">medrxiv</a>]
      [<a href="https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocaa076/5858301">online</a>]
      <br /><br />
      S. Yadlowsky S, R.A. Hayward, J.B. Sussman, R.L. McClelland, Y. Min, S. Basu.
      Clinical Implications of Revised Pooled Cohort Equations for Estimating
      Atherosclerotic Cardiovascular Disease Risk. Ann Intern Med. 5 June 2018. doi: <a href="https://doi.org/10.7326/M17-3011">10.7326/M17-3011<a>.
      <br /><br />
      T. Hashimoto, S. Yadlowsky, and J. Duchi. Reducing optimization to
      repeated classification. <i>Artificial Intelligence and Statistics, 21st
      International Conference (AISTATS)</i>, 2018.
      <br /><br />
      H. Namkoong, A. Sinha, S. Yadlowsky, and J. Duchi. Adaptive Sampling
      Probabilities for Non-Smooth Optimization. <i>International Conference on
      Machine Learning, Proceedings of the 34th</i>, 2017.
      [<a href="https://github.com/duchi-lab/adaptive-sampling-descent">code</a>]
      [<a href="http://proceedings.mlr.press/v70/namkoong17a.html">abstract</a>]
      [<a href="http://proceedings.mlr.press/v70/namkoong17a/namkoong17a.pdf">pdf</a>].
      <br /><br />
      S. Yadlowsky, J. Thai, C. Wu, A. Pozdnukhov, and A. Bayen. Link Density
      Inference from Cellular Infrastructure. <i>Transportation Research Board
      (TRB) 94th Annual Meeting, Proceedings of</i>, 2015.
      <br /><br />
      S. Yadlowsky, P. Nakkiran, J. Wang, R. Sharma, and L. El Ghaoui. Iterative
      Hard Thresholding for Keyword Extraction from Large Text
      Corpora. <i>Machine Learning and Applications (ICMLA), 14th International
      Conference on</i>, 2014.
      [<a href="https://github.com/syadlowsky/ihtpy">code</a>]
      [<a href="https://people.eecs.berkeley.edu/~elghaoui/pubs_icmla14.html">abstract</a>]
      [<a href="https://people.eecs.berkeley.edu/~elghaoui/Pubs/IhtSummarizationIMCLA14.pdf">pdf</a>].
      <br /><br />
      C. Wu, J. Thai, S. Yadlowsky, A. Pozdnukhov, and A. Bayen. Cellpath:
      fusion of cellular and traffic sensor data for route flow estimation via
      convex optimization. <i>Transportation and Traffic Theory, 21st
      International Symposium on</i>, 2014.
      <br /><br />
      J. Thai, C. Wu, S. Yadlowsky, A. Pozdnukhov, and A. Bayen. Solving
      simplex-constrained programs with efficient projections via isotonic
      regression. Poster presented at <i>Bay Area Machine Learning
      Symposium</i>, 2014.
      <br /><br />
      * Asterisk indicates co-first authorship.
    </p>
  </body>
</html>

